{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## About Project\n",
        "This is an English to Spanish Translator. The model is a LSTM based encoder-decoder with Bahdanau (Additive) Attention Mechanism. The model is trained on 45,000 sentence pairs."
      ],
      "metadata": {
        "id": "jaeB-QeHsAN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "7n0rLsmD1b-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Concatenate, Layer\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "6zDkaTLUoozQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset\n",
        "The csv file contains 1.5 lakh entries. We train our model on subset of 60,000 entries randomly selected from it.\n"
      ],
      "metadata": {
        "id": "dHbeIQFq5Qkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Load CSV & Set Columns\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "df.columns = ['English', 'Spanish']\n",
        "df = df.dropna()\n",
        "df = df.sample(n=60000, random_state=42).reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "WoW8jM3Do1kQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualising Dataset"
      ],
      "metadata": {
        "id": "GdfLVYJd10ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ihRB84no1ncb",
        "outputId": "d7b9d5f1-d59d-4307-cb81-fa0522dccaf3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          English  \\\n",
              "0                                     How boring!   \n",
              "1                                  I love sports.   \n",
              "2                    Would you like to swap jobs?   \n",
              "3                 My mother did nothing but weep.   \n",
              "4  Croatia is in the southeastern part of Europe.   \n",
              "\n",
              "                                         Spanish  \n",
              "0                             ¡Qué aburrimiento!  \n",
              "1                              Adoro el deporte.  \n",
              "2  ¿Te gustaría que intercambiemos los trabajos?  \n",
              "3             Mi madre no hizo nada sino llorar.  \n",
              "4          Croacia está en el sudeste de Europa.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0627a6f-b1d3-4138-bd08-cdeaa103b3e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Spanish</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How boring!</td>\n",
              "      <td>¡Qué aburrimiento!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love sports.</td>\n",
              "      <td>Adoro el deporte.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Would you like to swap jobs?</td>\n",
              "      <td>¿Te gustaría que intercambiemos los trabajos?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My mother did nothing but weep.</td>\n",
              "      <td>Mi madre no hizo nada sino llorar.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Croatia is in the southeastern part of Europe.</td>\n",
              "      <td>Croacia está en el sudeste de Europa.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0627a6f-b1d3-4138-bd08-cdeaa103b3e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0627a6f-b1d3-4138-bd08-cdeaa103b3e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0627a6f-b1d3-4138-bd08-cdeaa103b3e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8959efcb-6523-4b03-b5ba-913e72f5bd97\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8959efcb-6523-4b03-b5ba-913e72f5bd97')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8959efcb-6523-4b03-b5ba-913e72f5bd97 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 60000,\n  \"fields\": [\n    {\n      \"column\": \"English\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 55449,\n        \"samples\": [\n          \"How often do you feed the fish?\",\n          \"Tom had no intention of giving Mary any money.\",\n          \"My sister is a twenty-one years old college student.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spanish\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 58469,\n        \"samples\": [\n          \"Soy optimista por naturaleza.\",\n          \"\\u00bfEs verdad que los inmigrantes ilegales est\\u00e1n quitando puestos de trabajo a los ciudadanos que los quieren?\",\n          \"Ella tiene una rosa en la mano.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Text\n",
        "Lowercasing,Punctuation Removal, Addition of <start> and <end> tokens."
      ],
      "metadata": {
        "id": "0LteZkh22JRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "def preprocess_text(text, filters=''):\n",
        "    text = text.lower().strip()\n",
        "    if filters != '':\n",
        "        text = re.sub(filters, ' ', text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text\n",
        "\n",
        "df['English'] = df['English'].apply(lambda x: preprocess_text(x, filters='[^a-zA-ZÀ-ÿ0-9?.!,¿]+'))\n",
        "df['Spanish'] = df['Spanish'].apply(lambda x: \"<start> \" + preprocess_text(x, filters='[^a-zA-ZÀ-ÿ0-9?.!,¿]+') + \" <end>\")"
      ],
      "metadata": {
        "id": "_k_pfviFo7T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization and Padding of Sequences"
      ],
      "metadata": {
        "id": "W2TVErVK2Txw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization & Padding\n",
        "eng_tokenizer = Tokenizer(num_words=20000, oov_token='<unk>',filters='')\n",
        "eng_tokenizer.fit_on_texts(df['English'])\n",
        "X_enc = eng_tokenizer.texts_to_sequences(df['English'])\n",
        "\n",
        "sp_tokenizer = Tokenizer(num_words=20000, oov_token='<unk>',filters='')\n",
        "sp_tokenizer.fit_on_texts(df['Spanish'])\n",
        "X_dec = sp_tokenizer.texts_to_sequences(df['Spanish'])\n",
        "\n",
        "max_enc_len = max(len(seq) for seq in X_enc)\n",
        "max_dec_len = max(len(seq) for seq in X_dec)\n",
        "\n",
        "X_enc = pad_sequences(X_enc, maxlen=max_enc_len, padding='post')\n",
        "X_dec = pad_sequences(X_dec, maxlen=max_dec_len, padding='post')\n",
        "\n",
        "y_dec = np.zeros_like(X_dec)\n",
        "y_dec[:, :-1] = X_dec[:, 1:]\n",
        "y_dec[:, -1] = sp_tokenizer.word_index['<end>']"
      ],
      "metadata": {
        "id": "0WveAxZ0pDBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Validation Dataset Split"
      ],
      "metadata": {
        "id": "aCHvTyyB2h5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-validation split\n",
        "X_train_enc, X_val_enc, X_train_dec, X_val_dec, y_train, y_val = train_test_split(\n",
        "    X_enc, X_dec, y_dec, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "vY_y9Gz1pIA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bahdanau Attention Mechanism from scratch"
      ],
      "metadata": {
        "id": "DLJdW0Ni2pLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bahdanau Attention Layer\n",
        "\n",
        "class BahdanauAttention(Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = Dense(units)\n",
        "        self.W2 = Dense(units)\n",
        "        self.V = Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        # query: decoder outputs (batch, T_dec, units)\n",
        "        # values: encoder outputs (batch, T_enc, units)\n",
        "        query_with_time_axis = tf.expand_dims(query, 2)  # (batch, T_dec, 1, units)\n",
        "        values_with_time_axis = tf.expand_dims(values, 1)  # (batch, 1, T_enc, units)\n",
        "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values_with_time_axis)))\n",
        "        attention_weights = tf.nn.softmax(score, axis=2)  # (batch, T_dec, T_enc, 1)\n",
        "        context_vector = tf.matmul(tf.squeeze(attention_weights, -1), values)  # (batch, T_dec, units)\n",
        "        return context_vector\n"
      ],
      "metadata": {
        "id": "DVO_c2vKpLtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Based Encoder-Decoder with Attention"
      ],
      "metadata": {
        "id": "HzwJn6d227Rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Build LSTM Encoder-Decoder with Attention\n",
        "units = 128\n",
        "embedding_dim = 128\n",
        "enc_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "dec_vocab_size = len(sp_tokenizer.word_index) + 1\n",
        "\n",
        "# Encoder\n",
        "enc_in = Input(shape=(None,))\n",
        "enc_emb = Embedding(enc_vocab_size, embedding_dim)(enc_in)\n",
        "enc_out, enc_state_h, enc_state_c = LSTM(units, return_sequences=True, return_state=True)(enc_emb)\n",
        "\n",
        "# Decoder\n",
        "dec_in = Input(shape=(None,))\n",
        "dec_emb = Embedding(dec_vocab_size, embedding_dim)(dec_in)\n",
        "dec_out, _, _ = LSTM(units, return_sequences=True, return_state=True)(dec_emb, initial_state=[enc_state_h, enc_state_c])\n",
        "\n",
        "# Attention\n",
        "attention_layer = BahdanauAttention(units)\n",
        "context = attention_layer(dec_out, enc_out)\n",
        "concat = Concatenate(axis=-1)([dec_out, context])\n",
        "\n",
        "# Output\n",
        "logits = Dense(dec_vocab_size, activation='softmax')(concat)"
      ],
      "metadata": {
        "id": "_jdB_1DqpSch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Description"
      ],
      "metadata": {
        "id": "fGvfrImn3EBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "model = Model([enc_in, dec_in], logits)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "ufdFQj9kpXhJ",
        "outputId": "bf6e5c20-39e4-4ec2-ff2a-ed2d945ba375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_20        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m2,205,696\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_21        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m3,711,744\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m131,584\u001b[0m │ embedding_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m131,584\u001b[0m │ embedding_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bahdanau_attention… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m33,153\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mBahdanauAttention\u001b[0m) │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bahdanau_attenti… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m7,452,486\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m28998\u001b[0m)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_20        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,205,696</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_21        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,711,744</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ embedding_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ embedding_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bahdanau_attention… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,153</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BahdanauAttention</span>) │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bahdanau_attenti… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,452,486</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">28998</span>)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,666,247\u001b[0m (52.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,666,247</span> (52.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,666,247\u001b[0m (52.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,666,247</span> (52.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Tensorflow Dataset"
      ],
      "metadata": {
        "id": "dvdXa9YO3OaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.data.Dataset\n",
        "\n",
        "batch_size = 64\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(((X_train_enc, X_train_dec), np.expand_dims(y_train, -1)))\n",
        "train_dataset = train_dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(((X_val_enc, X_val_dec), np.expand_dims(y_val, -1)))\n",
        "val_dataset = val_dataset.batch(batch_size, drop_remainder=True)\n"
      ],
      "metadata": {
        "id": "_i_f6_HvpboX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "2aNEcxmZ3T73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfXP_vrNpfgc",
        "outputId": "4b4f12c2-3df1-43d2-ba3a-28e7038da126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 212ms/step - accuracy: 0.8487 - loss: 1.8191 - val_accuracy: 0.8911 - val_loss: 0.7675\n",
            "Epoch 2/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 212ms/step - accuracy: 0.8940 - loss: 0.7318 - val_accuracy: 0.8998 - val_loss: 0.6737\n",
            "Epoch 3/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 212ms/step - accuracy: 0.9027 - loss: 0.6335 - val_accuracy: 0.9088 - val_loss: 0.5997\n",
            "Epoch 4/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 212ms/step - accuracy: 0.9127 - loss: 0.5473 - val_accuracy: 0.9169 - val_loss: 0.5373\n",
            "Epoch 5/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 212ms/step - accuracy: 0.9219 - loss: 0.4665 - val_accuracy: 0.9234 - val_loss: 0.4851\n",
            "Epoch 6/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 212ms/step - accuracy: 0.9308 - loss: 0.3926 - val_accuracy: 0.9298 - val_loss: 0.4426\n",
            "Epoch 7/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 212ms/step - accuracy: 0.9389 - loss: 0.3285 - val_accuracy: 0.9342 - val_loss: 0.4129\n",
            "Epoch 8/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 212ms/step - accuracy: 0.9455 - loss: 0.2779 - val_accuracy: 0.9369 - val_loss: 0.3930\n",
            "Epoch 9/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 212ms/step - accuracy: 0.9517 - loss: 0.2346 - val_accuracy: 0.9391 - val_loss: 0.3809\n",
            "Epoch 10/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 213ms/step - accuracy: 0.9572 - loss: 0.2016 - val_accuracy: 0.9404 - val_loss: 0.3734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translate a few Sentences"
      ],
      "metadata": {
        "id": "ovLuGNkx39Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence, max_dec_len=max_dec_len):\n",
        "    # Preprocess input\n",
        "    sentence = preprocess_text(sentence)\n",
        "    seq = eng_tokenizer.texts_to_sequences([sentence])\n",
        "    seq = pad_sequences(seq, maxlen=max_enc_len, padding='post')\n",
        "\n",
        "    # Decoder starts with <start> token\n",
        "    start_id = sp_tokenizer.word_index['<start>']\n",
        "    end_id = sp_tokenizer.word_index['<end>']\n",
        "\n",
        "    dec_seq = np.zeros((1, max_dec_len))\n",
        "    dec_seq[0, 0] = start_id  # put <start> at first position\n",
        "\n",
        "    words = []\n",
        "    for i in range(1, max_dec_len):\n",
        "        pred = model.predict([seq, dec_seq], verbose=0)\n",
        "        pred_id = np.argmax(pred[0, i-1])  # predict next word\n",
        "        if pred_id == end_id:\n",
        "            break\n",
        "        if pred_id != 0:  # ignore padding\n",
        "            words.append(sp_tokenizer.index_word.get(pred_id, ''))\n",
        "        dec_seq[0, i] = pred_id  # feed predicted token back into decoder\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Translate Some Example Sentences\n",
        "\n",
        "for sentence in df['English'][:10]:\n",
        "    translation = translate(sentence, max_dec_len)\n",
        "    print(f\"English: {sentence}\")\n",
        "    print(f\"Predicted Spanish: {translation}\")\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFVR3WtnxUAN",
        "outputId": "d1ecb7d3-cef5-4ca0-bbe8-44061d1bc974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: how boring!\n",
            "Predicted Spanish: qué <unk>\n",
            "----------------------------------------\n",
            "English: i love sports.\n",
            "Predicted Spanish: me encanta los deportes.\n",
            "----------------------------------------\n",
            "English: would you like to swap jobs?\n",
            "Predicted Spanish: ¿te gustaría que intercambiemos los trabajos?\n",
            "----------------------------------------\n",
            "English: my mother did nothing but weep.\n",
            "Predicted Spanish: mi madre no hizo nada más que llorar.\n",
            "----------------------------------------\n",
            "English: croatia is in the southeastern part of europe.\n",
            "Predicted Spanish: pekín es en el volumen de europa.\n",
            "----------------------------------------\n",
            "English: i have never eaten a mango before.\n",
            "Predicted Spanish: nunca he comido un mango.\n",
            "----------------------------------------\n",
            "English: tell the taxi driver to drive faster.\n",
            "Predicted Spanish: dile al que <unk> a un <unk> y a john.\n",
            "----------------------------------------\n",
            "English: tom and i work together.\n",
            "Predicted Spanish: tom y yo trabajamos juntos.\n",
            "----------------------------------------\n",
            "English: i would prefer an honorable death.\n",
            "Predicted Spanish: prefiero una <unk> honorable.\n",
            "----------------------------------------\n",
            "English: tom married a much younger woman.\n",
            "Predicted Spanish: tom se casó mucho más joven con cuidado.\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating on Validation Set(Test Accuracy) 94%"
      ],
      "metadata": {
        "id": "8aBHQFYm3zET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Evaluate on Validation Set\n",
        "\n",
        "val_loss, val_acc = model.evaluate(val_dataset)\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEOcoeMGxtg9",
        "outputId": "5a47e285-a326-47f9-ff6d-8ebadc39f577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 173ms/step - accuracy: 0.9400 - loss: 0.3787\n",
            "Validation Loss: 0.3734\n",
            "Validation Accuracy: 0.9404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BLEU Score on 500 samples"
      ],
      "metadata": {
        "id": "323VSSlK4c1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def evaluate_bleu(model, X_enc_samples, X_dec_samples, sp_tokenizer, max_enc_len, max_dec_len, n_samples=500):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    1.model: trained Keras seq2seq model\n",
        "    2.X_enc_samples: encoder input sequences (English)\n",
        "    3.X_dec_samples: decoder target sequences (Spanish)\n",
        "    4.sp_tokenizer: Spanish tokenizer\n",
        "    5.max_enc_len, max_dec_len: maximum sequence lengths\n",
        "    6.n_samples: number of samples to evaluate (default 500)\n",
        "\n",
        "    Returns:\n",
        "    - BLEU score (corpus-level)\n",
        "    \"\"\"\n",
        "    start_token = sp_tokenizer.word_index['<start>']\n",
        "    end_token = sp_tokenizer.word_index['<end>']\n",
        "\n",
        "    references = []\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(min(n_samples, len(X_enc_samples))):\n",
        "        enc_seq = X_enc_samples[i:i+1]  # batch of 1\n",
        "        dec_seq_true = X_dec_samples[i]\n",
        "\n",
        "        # Reference sequence (remove <start> and <end>)\n",
        "        ref_tokens = [sp_tokenizer.index_word[tok]\n",
        "                      for tok in dec_seq_true if tok > 0 and tok != start_token and tok != end_token]\n",
        "        references.append([ref_tokens])\n",
        "\n",
        "        # Generate translation\n",
        "        dec_input = np.array([[start_token]])\n",
        "        translated = []\n",
        "\n",
        "        for _ in range(max_dec_len):\n",
        "            preds = model.predict([enc_seq, dec_input], verbose=0)\n",
        "            next_token = np.argmax(preds[0, -1, :])\n",
        "            if next_token == end_token:\n",
        "                break\n",
        "            translated.append(next_token)\n",
        "            dec_input = np.append(dec_input, [[next_token]], axis=1)\n",
        "\n",
        "        pred_tokens = [sp_tokenizer.index_word.get(tok, '') for tok in translated]\n",
        "        predictions.append(pred_tokens)\n",
        "\n",
        "    # Compute corpus BLEU score\n",
        "    bleu_score = corpus_bleu(references, predictions)\n",
        "    return bleu_score\n"
      ],
      "metadata": {
        "id": "4tlgQsE5zhfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score = evaluate_bleu(\n",
        "    model,\n",
        "    X_val_enc,\n",
        "    X_val_dec,\n",
        "    sp_tokenizer,\n",
        "    max_enc_len,\n",
        "    max_dec_len,\n",
        "    n_samples=500\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2KcV7h6zyfN",
        "outputId": "fb874dc6-84a2-4061-d5c3-0a4eb36d3d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation BLEU score (on 500 samples): 0.2201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Validation BLEU score (on 500 samples): {bleu_score*100:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxkd2rqE1Dyb",
        "outputId": "2037dbb7-7bb8-47b5-be73-ea014005e455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation BLEU score (on 500 samples): 22.0135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion:\n",
        " Accuracy of my Model is 94% on validtion dataset indicating it is predicting the right words.It also shows that model has understood the vocabulary well and has achieved token level fluency. But,the BLEU score is not upto the mark showing grammatical inaccuracies and overfitting to frequent words.\n",
        " ## Possible Updates to Model:\n",
        " Use of Bidirectional Encoder, Tuning Embedding and hidden sizes. Trying different attention mechanisms like Luong. Adding Layer Normalisation.\n",
        "\n",
        " Use of Advanced models like Transformers with multihead attention."
      ],
      "metadata": {
        "id": "Z8SlIoFxyV0R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXhnnki0xHar"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
